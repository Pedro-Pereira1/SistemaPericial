{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-5R0L9vKR3R"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "N6_fa_xmKR3R"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import joblib\n",
    "import matplotlib as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Conv1D, MaxPooling1D, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import ParameterGrid, cross_val_score\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pandas as pd\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oqAPKYpzKR3S"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eSP2ARbDKR3S"
   },
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_parquet(\"data/cic-collection.parquet\")  # Replace with the correct path to the dataset\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop(['Label','ClassLabel'], axis=1)  # Replace 'target' with the correct column name\n",
    "y = data['ClassLabel']\n",
    "\n",
    "# Encode target if categorical\n",
    "if y.dtype == 'object':\n",
    "    y = pd.factorize(y)[0]\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, stratify=y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "u2eWpRpLKR3S"
   },
   "outputs": [],
   "source": [
    "# Reduce the size of the dataset for faster training\n",
    "X_train = X_train[:10000]\n",
    "y_train = y_train[:10000]\n",
    "X_test = X_test[:1000]\n",
    "y_test = y_test[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yqg8kjnqKR3S"
   },
   "source": [
    "# Function to calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "gz1PchGSKR3S"
   },
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred, training_time, inference_time):\n",
    "    return {\n",
    "        \"Accuracy\": round(accuracy_score(y_true, y_pred), 4),\n",
    "        \"Precision\": round(precision_score(y_true, y_pred, average=\"weighted\"), 4),\n",
    "        \"Recall\": round(recall_score(y_true, y_pred, average=\"weighted\"), 4),\n",
    "        \"F1\": round(f1_score(y_true, y_pred, average=\"weighted\"), 4),\n",
    "        \"Training Time\": round(training_time, 4),\n",
    "        \"Inference Time\": round(inference_time, 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9Tt7I-YKR3S"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia8QnpasKR3S"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Hyperparameter grid\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5,]\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = list(itertools.product(\n",
    "    param_grid_rf['n_estimators'],\n",
    "    param_grid_rf['max_depth'],\n",
    "    param_grid_rf['min_samples_split']\n",
    "))\n",
    "\n",
    "# Initialize progress bar\n",
    "progress_bar = tqdm(total=len(all_params), desc=\"Training models\", unit=\"model\")\n",
    "\n",
    "best_score = -1\n",
    "best_params = None\n",
    "cv_results = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for params in all_params:\n",
    "    # Unpack parameters\n",
    "    param_dict = {\n",
    "        'n_estimators': params[0],\n",
    "        'max_depth': params[1],\n",
    "        'min_samples_split': params[2]\n",
    "    }\n",
    "    \n",
    "    # Update model with current parameters\n",
    "    rf.set_params(**param_dict)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    \n",
    "    # Save results\n",
    "    cv_results.append({**param_dict, 'mean_f1': mean_score, 'std_f1': std_score})\n",
    "    \n",
    "    # Update best parameters if needed\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = param_dict\n",
    "    \n",
    "    # Update progress bar\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "\n",
    "training_time_rf = time.time() - start_time\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_rf = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "start_time = time.time()\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "inference_time_rf = time.time() - start_time\n",
    "\n",
    "metrics_rf = calculate_metrics(y_test, y_pred_rf, training_time_rf, inference_time_rf)\n",
    "print(\"Random Forest Metrics:\", metrics_rf)\n",
    "\n",
    "# Save results and the best model\n",
    "results_rf = pd.DataFrame(cv_results)\n",
    "results_rf.to_csv('gridsearch_rf_results.csv', index=False)\n",
    "print(\"GridSearchCV results saved to 'gridsearch_rf_results.csv'.\")\n",
    "\n",
    "joblib.dump(best_rf, \"best_random_forest_model.pkl\")\n",
    "print(\"Model saved as 'best_random_forest_model.pkl'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  # Use MinMaxScaler() if you prefer normalization to [0, 1]\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u60Sb8fpKR3S"
   },
   "source": [
    "# XGBoost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oN0ODUBkKR3T"
   },
   "outputs": [],
   "source": [
    "# Define the model and hyperparameter grid\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    use_label_encoder=False, eval_metric='mlogloss', random_state=42, tree_method='gpu_hist'\n",
    ")\n",
    "\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [6, 10],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = list(ParameterGrid(param_grid_xgb))\n",
    "\n",
    "# Initialize progress bar\n",
    "progress_bar = tqdm(total=len(all_params), desc=\"Training XGBoost models\", unit=\"model\")\n",
    "\n",
    "# To store results\n",
    "cv_results = []\n",
    "best_score = -1\n",
    "best_params = None\n",
    "\n",
    "# Start grid search\n",
    "start_time = time.time()\n",
    "for params in all_params:\n",
    "    # Update the model with the current parameters\n",
    "    xgb_model.set_params(**params)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(xgb_model, X_train, y_train, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
    "    scores = scores[~np.isnan(scores)]\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    \n",
    "    # Save results\n",
    "    cv_results.append({**params, 'mean_f1': mean_score, 'std_f1': std_score})\n",
    "\n",
    "    # Update best parameters\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "\n",
    "    # Update progress bar\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "training_time_xgb = time.time() - start_time\n",
    "\n",
    "\n",
    "\n",
    "# Save results\n",
    "results_xgb = pd.DataFrame(cv_results)\n",
    "results_xgb.to_csv('gridsearch_xgb_results.csv', index=False)\n",
    "print(\"GridSearchCV results saved to 'gridsearch_xgb_results.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rxQBgxE5KR3T"
   },
   "source": [
    "# LightGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OP6EZ3cdKR3T"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training LGBM models: 100%|██████████| 16/16 [53:01<00:00, 198.86s/model]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV results saved to 'gridsearch_lgbm_results.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the model and hyperparameter grid\n",
    "lgbm = LGBMClassifier()\n",
    "\n",
    "param_grid_lgbm = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'max_depth': [-1, 10],\n",
    "    'num_leaves': [31, 63]\n",
    "}\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = list(ParameterGrid(param_grid_lgbm))\n",
    "\n",
    "# Initialize progress bar\n",
    "progress_bar = tqdm(total=len(all_params), desc=\"Training LGBM models\", unit=\"model\")\n",
    "\n",
    "# To store results\n",
    "cv_results = []\n",
    "best_score = -1\n",
    "best_params = None\n",
    "\n",
    "# Start grid search\n",
    "start_time = time.time()\n",
    "for params in all_params:\n",
    "    # Update the model with the current parameters\n",
    "    lgbm.set_params(**params)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    scores = cross_val_score(lgbm, X_train, y_train, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "    mean_score = scores.mean()\n",
    "    std_score = scores.std()\n",
    "    \n",
    "    # Save results\n",
    "    cv_results.append({**params, 'mean_f1': mean_score, 'std_f1': std_score})\n",
    "    \n",
    "    # Update best parameters\n",
    "    if mean_score > best_score:\n",
    "        best_score = mean_score\n",
    "        best_params = params\n",
    "\n",
    "    # Update progress bar\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "training_time_lgbm = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results_lgbm = pd.DataFrame(cv_results)\n",
    "results_lgbm.to_csv('gridsearch_lgbm_results.csv', index=False)\n",
    "print(\"GridSearchCV results saved to 'gridsearch_lgbm_results.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WPsBkQOKR3T"
   },
   "source": [
    "# CNN + RNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7iMgRsOKR3T"
   },
   "outputs": [],
   "source": [
    "# Função para construir o modelo CNN+RNN\n",
    "def create_cnn_rnn_model(conv_filters=64, lstm_units=64, dense_units=128, dropout_rate=0.5, learning_rate=0.001):\n",
    "    model = Sequential([\n",
    "        Conv1D(conv_filters, 3, activation='relu', kernel_initializer='he_uniform', input_shape=(X_train_dl.shape[1], 1)),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        LSTM(lstm_units, return_sequences=False),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(dense_units, activation='relu', kernel_initializer='he_uniform'),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(len(np.unique(y_train)), activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Reduzindo o grid de parâmetros\n",
    "param_grid_cnn_rnn = {\n",
    "    'conv_filters': [32, 64],\n",
    "    'lstm_units': [64, 128],\n",
    "    'dense_units': [64, 128],\n",
    "    'dropout_rate': [0.3, 0.5],\n",
    "    'batch_size': [32],\n",
    "    'epochs': [10, 20],\n",
    "    'learning_rate': [0.001]  # Mantendo fixo para reduzir busca\n",
    "}\n",
    "\n",
    "# Reorganizar os dados\n",
    "X_train_dl = np.expand_dims(X_train, axis=2)\n",
    "X_test_dl = np.expand_dims(X_test, axis=2)\n",
    "y_train_dl = to_categorical(y_train)\n",
    "y_test_dl = to_categorical(y_test)\n",
    "\n",
    "# Grid Search\n",
    "all_params = list(ParameterGrid(param_grid_cnn_rnn))\n",
    "cv_results = []\n",
    "best_score = -1\n",
    "best_params = None\n",
    "start_time = time.time()\n",
    "\n",
    "# Estratégia k-fold\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "print(f\"Total parameter combinations: {len(all_params)}\")\n",
    "progress_bar = tqdm(total=len(all_params), desc=\"Training CNN+RNN models\", unit=\"model\")\n",
    "\n",
    "# Realiza grid search\n",
    "for params in all_params:\n",
    "    fold_scores = []\n",
    "\n",
    "    for train_idx, val_idx in kfold.split(X_train_dl, y_train):\n",
    "        # Separar treinamento e validação\n",
    "        X_train_fold, X_val_fold = X_train_dl[train_idx], X_train_dl[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_dl[train_idx], y_train_dl[val_idx]\n",
    "\n",
    "        # Criar o modelo\n",
    "        model = create_cnn_rnn_model(\n",
    "            conv_filters=params['conv_filters'],\n",
    "            lstm_units=params['lstm_units'],\n",
    "            dense_units=params['dense_units'],\n",
    "            dropout_rate=params['dropout_rate'],\n",
    "            learning_rate=params['learning_rate']\n",
    "        )\n",
    "\n",
    "        # Treinar o modelo com early stopping\n",
    "        early_stop = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True, verbose=0)\n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            batch_size=params['batch_size'],\n",
    "            epochs=params['epochs'],\n",
    "            verbose=0,\n",
    "            callbacks=[early_stop]\n",
    "        )\n",
    "\n",
    "        # Avaliar no conjunto de validação\n",
    "        score = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n",
    "        fold_scores.append(score[1])  # Pega a acurácia\n",
    "\n",
    "    # Média das acurácias dos folds\n",
    "    avg_score = np.mean(fold_scores)\n",
    "    cv_results.append({**params, 'accuracy': avg_score})\n",
    "\n",
    "    # Atualiza melhor modelo se necessário\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_params = params\n",
    "        best_model = model\n",
    "\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()\n",
    "training_time_cnn_rnn = time.time() - start_time\n",
    "\n",
    "# Salvar resultados\n",
    "results_cnn_rnn = pd.DataFrame(cv_results)\n",
    "results_cnn_rnn.to_csv('gridsearch_cnn_rnn_results.csv', index=False)\n",
    "\n",
    "print(f\"GridSearch completed in {training_time_cnn_rnn:.2f} seconds.\")\n",
    "print(f\"Best Accuracy: {best_score:.4f} with params: {best_params}\")\n",
    "print(\"GridSearch results saved to 'gridsearch_cnn_rnn_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JbZs7at8KR3T"
   },
   "source": [
    "# Save metrics\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
